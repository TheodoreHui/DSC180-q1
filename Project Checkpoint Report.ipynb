{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3237b734",
   "metadata": {},
   "source": [
    "# Reproducing Text Classification Methods From ConWea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b77c9",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "   Weakly supervised text classification is a research area that aims to address the challenges of classifying text documents when labeled data is scarce or expensive to obtain. Unlike traditional supervised learning, which relies on fully labeled datasets, weakly supervised methods make use of partially labeled sources to train classification models. This project seeks to reproduce baseline weakly supervised text classifications from the ConWea paper, namely TF-IDF(Term Frequency-Inverse Document Frequency) and Word2Vec. TF-IDF creates word weights by comparing a word's frequency in a given document to its overall frequency in the corpus. Word2Vec, on the other hand, creates vector representations of words using neural nets, capturing more context in a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc61a016",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6c823",
   "metadata": {},
   "source": [
    "\n",
    "With the advent of large language models (LLMs), the demand for labeled text data has skyrocketed. Model parameters have skyrocket into the hundreds of billions, with millions of training tokens. GPT-4 is speculated to perhaps even break the trillion mark, following Moore's law. Text needs to be processed for training data on a scale never before seen to feed these models. In the past, labeling was done manually, with OpenAI even paying workers in African less than 2 dollars a day for data that trained ChatGPT. However, using new technologies, this process could potentially become much more automated. This paper leverages loosely supervised rather than the manual strictly supervised method. These approaches involve using a small number of \"seed words\" to classify documents into different topics. That way, the only human labor required is the generation of seed words, which may even be eliminated later on.\n",
    "\n",
    "Article referencing OpenAI Kenyan Labor\n",
    "https://time.com/6247678/openai-chatgpt-kenya-workers/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45205c0d",
   "metadata": {},
   "source": [
    "### Lit Review\n",
    "Most relevant in this project is \"Contextualized Weak Supervision for Text Classification\" (ConWea) by Dheeraj Mekala and Jingbo Shang. This paper, in addition to the baseline models this project recreates, leverages BERT to as their vectorizer and a HAN classifier. Additionally, using the user provided seed words, the model automatically generates additional seed words that are similar occurances of the given words. \n",
    "\n",
    "The next evolution is \"X-Class: Text Classification with Extremely Weak Supervision\" by Zihan Wang, Dheeraj Mekala and Jingbo Shang. This paper eliminated the need for seed words, instead simply relying on class names to generate document representations (using BERT) in the context of the classes, which were then clustered and fed into a supervised text classifier. Despite having less starting information, this model outperformed ConWea in 5/6 tests.\n",
    "\n",
    "\"Goal-Driven Explainable Clustering via Language Descriptions\" by Zihan Wang, Jingbo Shang, and Ruiqi Zhong leverages 2 different language models rather then vectorizers, one to propose classes and one to create an assign matrix that sorts documents into said classes (each document can fall into multiple), and a final linear programming model to pick optimal classes\n",
    "\n",
    "The final paper discussed is \"CLUSTERLLM: Large Language Models as a Guide for Text Clustering\" by Yuwei Zhang, Zihan Wang Jingbo Shang. This paper uses the large language model ChatGPT to cluster as well as determine the optimal number of classes. This adds a direct computational cost as well as a lack of control over the embeddings since they beling to OpenAi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f741575",
   "metadata": {},
   "source": [
    "### Description of Data\n",
    "There were 2 given datasets, both of which were news articles. Each dataset was already labeled to give truth labels for our models. Additionally, both datasets came with a set of seedwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ca97ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "def load_json(path):\n",
    "    with open(path, 'r') as file:\n",
    "        return json.load(file)\n",
    "data20 = load_pickle('TrainingData/20news/df20.pkl')\n",
    "seed20 = load_json('TrainingData/20news/seedwords.json')\n",
    "datanyt = load_pickle('TrainingData/nyt/dfnyt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b87b6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from:  (where's my thing)\\nsubject: what car i...</td>\n",
       "      <td>rec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from:  (guy kuo)\\nsubject: si clock poll - fin...</td>\n",
       "      <td>comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from:  (thomas e willis)\\nsubject: pb question...</td>\n",
       "      <td>comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from: jgreen@amber (joe green)\\nsubject: re: w...</td>\n",
       "      <td>comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>from:  (jonathan mcdowell)\\nsubject: re: shutt...</td>\n",
       "      <td>sci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18254</th>\n",
       "      <td>from:  (stupendous man)\\nsubject: re: temperat...</td>\n",
       "      <td>sci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18255</th>\n",
       "      <td>from:  (jim smyton)\\nsubject: re: monitors - s...</td>\n",
       "      <td>comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18256</th>\n",
       "      <td>from: \\nsubject: re: game length (was re: brav...</td>\n",
       "      <td>rec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18257</th>\n",
       "      <td>from:  \\nsubject: intel chmos 8086/8088 design...</td>\n",
       "      <td>misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18258</th>\n",
       "      <td>from: \\nsubject: re: homosexuality issues in c...</td>\n",
       "      <td>soc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18259 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence label\n",
       "0      from:  (where's my thing)\\nsubject: what car i...   rec\n",
       "1      from:  (guy kuo)\\nsubject: si clock poll - fin...  comp\n",
       "2      from:  (thomas e willis)\\nsubject: pb question...  comp\n",
       "3      from: jgreen@amber (joe green)\\nsubject: re: w...  comp\n",
       "4      from:  (jonathan mcdowell)\\nsubject: re: shutt...   sci\n",
       "...                                                  ...   ...\n",
       "18254  from:  (stupendous man)\\nsubject: re: temperat...   sci\n",
       "18255  from:  (jim smyton)\\nsubject: re: monitors - s...  comp\n",
       "18256  from: \\nsubject: re: game length (was re: brav...   rec\n",
       "18257  from:  \\nsubject: intel chmos 8086/8088 design...  misc\n",
       "18258  from: \\nsubject: re: homosexuality issues in c...   soc\n",
       "\n",
       "[18259 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "442802b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt': ['atheism', 'atheists', 'religion', 'objective'],\n",
       " 'comp': ['graphics', 'windows', 'scsi', 'mac'],\n",
       " 'misc': ['sale', 'offer', 'shipping', 'forsale'],\n",
       " 'rec': ['car', 'bike', 'game', 'team'],\n",
       " 'sci': ['encryption', 'circuit', 'candida', 'space'],\n",
       " 'talk': ['turkish', 'gun', 'jews', 'armenian'],\n",
       " 'soc': ['church', 'jesus', 'christ', 'christians']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c30aa",
   "metadata": {},
   "source": [
    "As you can see below, the email dataset had a somewhat even distribution of labels compared to the NYT dataset, which was overwhelmingly of the 'sports' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed9eb14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " comp    4685\n",
       " sci     3879\n",
       " rec     3822\n",
       " talk    3180\n",
       " soc      988\n",
       " misc     912\n",
       " alt      793\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " sports      8448\n",
       " arts        1040\n",
       " politics     977\n",
       " business     973\n",
       " science       89\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data20['label'].value_counts(), datanyt['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c90e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
